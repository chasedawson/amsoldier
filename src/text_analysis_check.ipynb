{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/chasedawson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chasedawson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chasedawson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import nltk\n",
    "import collections\n",
    "import itertools\n",
    "import re \n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# text_col\n",
    "def get_words(text_col):\n",
    "    return [text.strip().split(' ') for text in text_col]\n",
    "\n",
    "def remove_stop_words(text_words):\n",
    "    return [list(filter(lambda x: x not in stop_words, words)) for words in text_words]\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(\"\\s\\s+\", \" \", text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "# look into part of speech tagging with nltk,\n",
    "# would make lemmatization more powerful\n",
    "def lemmatize(text_words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [[lemmatizer.lemmatize(word) for word in words] for words in text_words]\n",
    "\n",
    "def stem(df, word_col):\n",
    "    stemmer = PorterStemmer()\n",
    "    df[word_col] = df[word_col].apply(lambda x: stemmer.stem(x))\n",
    "    return df\n",
    "\n",
    "def stem2(text_words):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [[stemmer.stem(word) for word in words] for words in text_words]\n",
    "\n",
    "def preprocess(text_col, clean = \"stem\"):\n",
    "    text_col = text_col.apply(remove_punctuation)\n",
    "    text_col = text_col.apply(remove_extra_spaces)\n",
    "    text_words = remove_stop_words(get_words(text_col))\n",
    "\n",
    "    if clean == \"lemmatize\":\n",
    "        text_words = lemmatize(text_words)\n",
    "    else:\n",
    "        text_words = stem2(text_words)\n",
    "\n",
    "    return text_words\n",
    "\n",
    "def get_word_counts(text_col, clean = \"stem\"):\n",
    "    text_words = preprocess(text_col, clean = clean)\n",
    "\n",
    "    # flatten \n",
    "    words = [word for words in text_words for word in words]\n",
    "    word_counts = collections.Counter(words)\n",
    "\n",
    "    # convert to DataFrame and return\n",
    "    return pd.DataFrame(word_counts.most_common(), columns = [\"word\", \"count\"])\n",
    "\n",
    "# return Pandas DataFrame containing bigrams\n",
    "def get_bigrams(text_col, top_n = 500, clean = \"stem\"):\n",
    "    # extract words from text_col, remove stop words, and lemmatize\n",
    "    text_words = remove_stop_words(get_words(text_col))\n",
    "\n",
    "    if clean == \"lemmatize\":\n",
    "        text_words = lemmatize(text_words)\n",
    "    else:\n",
    "        text_words = stem(text_words)\n",
    "\n",
    "    terms_bigram = [list(bigrams(words)) for words in text_words]\n",
    "    bigrams = list(itertools.chain(*terms_bigram))\n",
    "    bigram_counts = collections.Counter(bigrams)\n",
    "    bigram_df = pd.DataFrame(bigram_counts.most_common(top_n), columns = ['bigram', 'count'])\n",
    "    bigram_df['item1'] = bigram_df.bigram.apply(lambda x: x[0])\n",
    "    bigram_df['item2'] = bigram_df.bigram.apply(lambda x: x[1])\n",
    "    bigram_df = bigram_df.drop(columns=['bigram'])\n",
    "    bigram_df = bigram_df[['item1', 'item2', 'count']]\n",
    "    return bigram_df\n",
    "\n",
    "\n",
    "def get_cooc_counts(text_col, clean = \"stem\"):\n",
    "    text_words = preprocess(text_col, clean = clean)\n",
    "    terms_cooc = [list(itertools.permutations(words, 2)) for words in text_words]\n",
    "    cooc = list(itertools.chain(*terms_cooc))\n",
    "    cooc_counts = collections.Counter(cooc)\n",
    "    return cooc_counts\n",
    "\n",
    "# get co-occurrences\n",
    "def get_cooc(text_col, clean = \"stem\", min_word_count = 10):\n",
    "    cooc_counts = get_cooc_counts(text_col, clean = clean)\n",
    "    cooc_df = make_dataframe(cooc_counts.most_common(), columns = ['cooc', 'count'])\n",
    "    word_counts = get_word_counts(text_col, clean = clean)\n",
    "\n",
    "    # only look at words that occur >= min_word_count\n",
    "    word_counts = word_counts[word_counts['count'] >= min_word_count]\n",
    "\n",
    "    # filter cooc such that each cooc is comprised of words that occur at least a certain number of times\n",
    "    # specified in the min_word_count variable\n",
    "    cooc_df = cooc_df[(cooc_df.item1.isin(word_counts.word)) & (cooc_df.item2.isin(word_counts.word))]\n",
    "    \n",
    "    # return only odd columns since cooc are doubly represented as item1,item2 then item2,item1 on following row\n",
    "    cooc_df = cooc_df.iloc[:-2:2]\n",
    "    \n",
    "    # remove rows where item1 == item2\n",
    "    cooc_df = cooc_df[cooc_df.item1 != cooc_df.item2]\n",
    "    \n",
    "    return cooc_df\n",
    "\n",
    "# columns should be a list of two elements: the first should contain the name of the column containing the word pair \n",
    "# (either a bigram or co-occurrence) and the second should contain the count. \n",
    "# columns[0] will be split into two columns, one for each word in the pair, and then the original column will be dropped.\n",
    "def make_dataframe(data, columns):\n",
    "    df = pd.DataFrame(data, columns = columns)\n",
    "    df['item1'] = df.cooc.apply(lambda x: x[0])\n",
    "    df['item2'] = df.cooc.apply(lambda x: x[1])\n",
    "    df = df.drop(columns=[columns[0]])\n",
    "    df = df[['item1', 'item2', columns[1]]]\n",
    "    return df\n",
    "\n",
    "def unnest_tokens(df, output_col, input_col, token = \"words\", to_lower = True, drop = True):\n",
    "    text_col = df[input_col]\n",
    "    tokens = {'id': [], output_col: []}\n",
    "    for i, text in text_col.iteritems():\n",
    "        for word in text.strip().split(' '):\n",
    "            tokens['id'].append(i)\n",
    "            tokens[output_col].append(word)\n",
    "    tokens_df = pd.DataFrame(tokens)\n",
    "    \n",
    "    if to_lower:\n",
    "        tokens_df[output_col] = tokens_df[output_col].apply(lambda x: x.lower())\n",
    "        \n",
    "    # remove entries where token is an empty string\n",
    "    tokens_df = tokens_df[tokens_df[output_col] != \"\"]\n",
    "    return tokens_df\n",
    "\n",
    "def get_token2doc_map(df, token_col, doc_id_col):\n",
    "    return { k[0]: { v: v for v in k[1].values } for k in df.groupby(token_col)[doc_id_col] }\n",
    "\n",
    "def get_word_doc_count(x, y, n_docs, word2doc_map):\n",
    "    # initialize counts\n",
    "    has_only_x_count = 0\n",
    "    has_only_y_count = 0\n",
    "    has_both_count = 0\n",
    "    has_neither_count = 0\n",
    "    \n",
    "    x_docs = word2doc_map[x]\n",
    "    y_docs = word2doc_map[y]\n",
    "    \n",
    "    if len(x_docs) <= len(y_docs):\n",
    "        for key in x_docs:\n",
    "            if key in y_docs:\n",
    "                has_both_count += 1\n",
    "    else:\n",
    "        for key in y_docs:\n",
    "            if key in x_docs:\n",
    "                has_both_count += 1\n",
    "                \n",
    "    has_only_x_count = len(x_docs) - has_both_count\n",
    "    has_only_y_count = len(y_docs) - has_both_count\n",
    "    has_neither_count = n_docs - has_both_count - has_only_x_count - has_only_y_count\n",
    "    \n",
    "    return {'only_x': has_only_x_count,\n",
    "            'only_y': has_only_y_count,\n",
    "            'both': has_both_count,\n",
    "            'neither': has_neither_count}\n",
    "    \n",
    "\n",
    "# count the number of documents in which each word occurs, retuning a dict where the word, count is the key, value\n",
    "def add_word_doc_counts(df, n_docs, word2doc_map):\n",
    "    print(\"add_word_doc_counts called\")\n",
    "    \n",
    "    has_item1_only = []\n",
    "    has_item2_only = []\n",
    "    has_both = []\n",
    "    has_neither = []\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        item1 = row['item1']\n",
    "        item2 = row['item2']\n",
    "        result = get_word_doc_count(item1, item2, n_docs, word2doc_map)\n",
    "        \n",
    "        # append counts to lists\n",
    "        has_item1_only.append(result['only_x'])\n",
    "        has_item2_only.append(result['only_y'])\n",
    "        has_both.append(result['both'])\n",
    "        has_neither.append(result['neither'])\n",
    "        \n",
    "    # add new columns to dataframe\n",
    "    df['has_item1_only'] = has_item1_only\n",
    "    df['has_item2_only'] = has_item2_only\n",
    "    df['has_both'] = has_both\n",
    "    df['has_neither'] = has_neither\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_phi_coeff(only_x, only_y, both, neither):\n",
    "    n11 = both\n",
    "    n10 = only_x\n",
    "    n01 = only_y\n",
    "    n00 = neither\n",
    "    n1_ = n11 + n10\n",
    "    n_1 = n11 + n01\n",
    "    n0_ = n00 + n01\n",
    "    n_0 = n00 + n10\n",
    "    \n",
    "    phi = ((n11 * n00) - (n10 * n01)) / (n1_ * n0_ * n_0 * n_1) ** 0.5\n",
    "    return phi\n",
    "\n",
    "    \n",
    "# get pairwise cor\n",
    "def get_pairwise_cor(df, text_col, clean = \"stem\", min_word_count = 10):\n",
    "    cooc_df = get_cooc(df[text_col], clean = clean, min_word_count = min_word_count)\n",
    "\n",
    "    # get total number of documents\n",
    "    n_docs = len(df[text_col])\n",
    "    \n",
    "    words = unnest_tokens(df, \"word\", text_col)\n",
    "    words_stem = stem(words, \"word\")\n",
    "    word2doc_map = get_token2doc_map(words_stem, \"word\", \"id\")\n",
    "\n",
    "    # compute phi coefficient\n",
    "    cor_df = add_word_doc_counts(cooc_df, n_docs, word2doc_map)\n",
    "    \n",
    "    cor_df['phi'] = get_phi_coeff(cor_df.has_item1_only, cor_df.has_item2_only, cor_df.has_both, cor_df.has_neither)\n",
    "\n",
    "    # return dataframe\n",
    "    return cor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s32_sentences = pd.read_csv('../data/s32_sentences_sent_df.csv', index_col=0)\n",
    "s32_sentences.sentence = s32_sentences.sentence.apply(remove_punctuation)\n",
    "s32_sentences.sentence = s32_sentences.sentence.apply(remove_extra_spaces)\n",
    "s32_sentences.sentence = s32_sentences.sentence.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>negro have been told many times they are fight...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.968257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>but a colored soldier is more discriminated ag...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.953218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>its evident to those who care to see it that n...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.973801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>since the emancipation proclamation negro have...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.823565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>each right each privilege was fought for</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.987902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   response_id                                           sentence sentiment  \\\n",
       "0            3  negro have been told many times they are fight...  NEGATIVE   \n",
       "1            3  but a colored soldier is more discriminated ag...  NEGATIVE   \n",
       "2            3  its evident to those who care to see it that n...  POSITIVE   \n",
       "3            3  since the emancipation proclamation negro have...  NEGATIVE   \n",
       "4            3           each right each privilege was fought for  POSITIVE   \n",
       "\n",
       "      score  \n",
       "0  0.968257  \n",
       "1  0.953218  \n",
       "2  0.973801  \n",
       "3  0.823565  \n",
       "4  0.987902  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s32_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = unnest_tokens(s32_sentences, \"word\", \"sentence\")\n",
    "words_stem = stem(words, \"word\")\n",
    "word2doc_map = get_token2doc_map(words_stem, \"word\", \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19834"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s32_sentences.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'only_x': 1099, 'only_y': 1723, 'both': 1003, 'neither': 16009}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_word_doc_count(\"white\", \"negro\", len(s32_sentences.sentence), word2doc_map)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19834"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['only_x'] + res['only_y'] + res['both'] + res['neither']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33971231434285887"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_phi_coeff(res['only_x'], res['only_y'], res['both'], res['neither'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "732it [00:00, 7318.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_word_doc_counts called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192675it [00:13, 14589.13it/s]\n"
     ]
    }
   ],
   "source": [
    "cor_df = get_pairwise_cor(s32_sentences, \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>count</th>\n",
       "      <th>has_item1_only</th>\n",
       "      <th>has_item2_only</th>\n",
       "      <th>has_both</th>\n",
       "      <th>has_neither</th>\n",
       "      <th>phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>negro</td>\n",
       "      <td>1635</td>\n",
       "      <td>1099</td>\n",
       "      <td>1723</td>\n",
       "      <td>1003</td>\n",
       "      <td>16009</td>\n",
       "      <td>0.339712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>soldier</td>\n",
       "      <td>white</td>\n",
       "      <td>1136</td>\n",
       "      <td>2074</td>\n",
       "      <td>1478</td>\n",
       "      <td>624</td>\n",
       "      <td>15658</td>\n",
       "      <td>0.161526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>soldier</td>\n",
       "      <td>negro</td>\n",
       "      <td>1099</td>\n",
       "      <td>2015</td>\n",
       "      <td>2043</td>\n",
       "      <td>683</td>\n",
       "      <td>15093</td>\n",
       "      <td>0.133347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>like</td>\n",
       "      <td>would</td>\n",
       "      <td>961</td>\n",
       "      <td>1085</td>\n",
       "      <td>1437</td>\n",
       "      <td>662</td>\n",
       "      <td>16650</td>\n",
       "      <td>0.275921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>color</td>\n",
       "      <td>white</td>\n",
       "      <td>807</td>\n",
       "      <td>613</td>\n",
       "      <td>1613</td>\n",
       "      <td>489</td>\n",
       "      <td>17119</td>\n",
       "      <td>0.266147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item1  item2  count  has_item1_only  has_item2_only  has_both  \\\n",
       "2     white  negro   1635            1099            1723      1003   \n",
       "6   soldier  white   1136            2074            1478       624   \n",
       "8   soldier  negro   1099            2015            2043       683   \n",
       "10     like  would    961            1085            1437       662   \n",
       "14    color  white    807             613            1613       489   \n",
       "\n",
       "    has_neither       phi  \n",
       "2         16009  0.339712  \n",
       "6         15658  0.161526  \n",
       "8         15093  0.133347  \n",
       "10        16650  0.275921  \n",
       "14        17119  0.266147  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16057026.954582293"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_df.phi[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006 1102 1721\n"
     ]
    }
   ],
   "source": [
    "item1_check = \"white\"\n",
    "item2_check = \"negro\"\n",
    "\n",
    "both = 0\n",
    "item1_count = 0\n",
    "item2_count = 0\n",
    "for doc in s32_sentences.sentence:\n",
    "    found1 = doc.find(item1_check) != -1\n",
    "    found2 = doc.find(item2_check) != -1\n",
    "    \n",
    "    if found1:\n",
    "        if found2:\n",
    "            both += 1\n",
    "        else:\n",
    "            item1_count += 1\n",
    "    elif found2:\n",
    "        item2_count += 1\n",
    "        \n",
    "print(both, item1_count, item2_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>negro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>told</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   word\n",
       "0   0  negro\n",
       "1   0   have\n",
       "2   0   been\n",
       "3   0   told\n",
       "4   0   many"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = unnest_tokens(s32_sentences, \"word\", \"sentence\")\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>negro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>told</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>mani</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   word\n",
       "0   0  negro\n",
       "1   0   have\n",
       "2   0   been\n",
       "3   0   told\n",
       "4   0   mani"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_stem = stem(words, \"word\")\n",
    "words_stem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2doc_map = get_token2doc_map(words_stem, \"word\", \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-9d069fd8570c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2doc_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'negro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2doc_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'have'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "np.array(list(word2doc_map['negro'].values()) + list(word2doc_map['have'].values())).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chasedawson/dev/sdad/amsoldier/src'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this has asdfasdf '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuation(\"this!! has asdfasdf ()()&&*&^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_ids</th>\n",
       "      <th>long</th>\n",
       "      <th>racial_group</th>\n",
       "      <th>outfits</th>\n",
       "      <th>outfits_comment</th>\n",
       "      <th>index</th>\n",
       "      <th>long_sentiment</th>\n",
       "      <th>long_score</th>\n",
       "      <th>outfits_sentiment</th>\n",
       "      <th>outfits_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20738627</td>\n",
       "      <td>negro have been told many times they are fight...</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.747680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20738629</td>\n",
       "      <td>i do not like the army. i had rather be on the...</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.996761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20738631</td>\n",
       "      <td>i think that if we are going to win this war, ...</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.996679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20738633</td>\n",
       "      <td>why is it that the negro do not have the the  ...</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.996114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20738636</td>\n",
       "      <td>i highly approve of this questionnaire it give...</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.996020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_ids                                               long racial_group  \\\n",
       "3    20738627  negro have been told many times they are fight...        black   \n",
       "4    20738629  i do not like the army. i had rather be on the...        black   \n",
       "5    20738631  i think that if we are going to win this war, ...        black   \n",
       "6    20738633  why is it that the negro do not have the the  ...        black   \n",
       "7    20738636  i highly approve of this questionnaire it give...        black   \n",
       "\n",
       "  outfits outfits_comment  index long_sentiment  long_score outfits_sentiment  \\\n",
       "3     NaN             NaN      3       NEGATIVE    0.747680               NaN   \n",
       "4     NaN             NaN      4       NEGATIVE    0.996761               NaN   \n",
       "5     NaN             NaN      5       NEGATIVE    0.996679               NaN   \n",
       "6     NaN             NaN      6       NEGATIVE    0.996114               NaN   \n",
       "7     NaN             NaN      7       POSITIVE    0.996020               NaN   \n",
       "\n",
       "   outfits_score  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "5            0.0  \n",
       "6            0.0  \n",
       "7            0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s32 = pd.read_csv('../data/s32_sent_df.csv', index_col=0)\n",
    "s32_sentences = pd.read_csv('../data/s32_sentences_sent_df.csv', index_col=0)\n",
    "s32.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>negro have been told many times they are fight...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.968257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>but a colored soldier is more discriminated ag...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.953218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>its evident to those who care to see it that n...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.973801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>since the emancipation proclamation negro have...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.823565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>each right, each privilege was fought for.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.987902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   response_id                                           sentence sentiment  \\\n",
       "0            3  negro have been told many times they are fight...  NEGATIVE   \n",
       "1            3  but a colored soldier is more discriminated ag...  NEGATIVE   \n",
       "2            3  its evident to those who care to see it that n...  POSITIVE   \n",
       "3            3  since the emancipation proclamation negro have...  NEGATIVE   \n",
       "4            3         each right, each privilege was fought for.  POSITIVE   \n",
       "\n",
       "      score  \n",
       "0  0.968257  \n",
       "1  0.953218  \n",
       "2  0.973801  \n",
       "3  0.823565  \n",
       "4  0.987902  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s32_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s32_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19834, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s32_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_df = get_cooc(s32_sentences.sentence, min_word_count = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326855, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [response_id, sentence, sentiment, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
